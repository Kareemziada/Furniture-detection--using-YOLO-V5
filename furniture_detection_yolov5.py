# -*- coding: utf-8 -*-
"""Furniture Detection YoloV5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RdRD_frWyACX4VcpO1-MPd-AbQ6s1xaM

# install Req's:
"""

!pip install roboflow

# clone YOLOv5 repository
!git clone https://github.com/ultralytics/yolov5  # clone repo

# Commented out IPython magic to ensure Python compatibility.
# %cd yolov5

!pip install -qr requirements.txt  # install dependencies (ignore errors)

"""# API Key from roboflow to get the dataset:"""

from roboflow import Roboflow
rf = Roboflow(api_key="eNXjhSbZVSSOMWRMmVIs")
project = rf.workspace("nos-tashteeb-2qzbe").project("furniture-detection-2kump")
version = project.version(2)
dataset = version.download("yolov5")

# Commented out IPython magic to ensure Python compatibility.
# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data
# %cat {dataset.location}/data.yaml

"""# Data preprocessing:"""

# define number of classes based on YAML
import yaml
with open(dataset.location + "/data.yaml", 'r') as stream:
    num_classes = str(yaml.safe_load(stream)['nc'])

"""# preparing the model for the task:"""

# Commented out IPython magic to ensure Python compatibility.
#this is the model configuration we will use for our tutorial
# %cat /content/yolov5/models/yolov5s.yaml

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))

# Commented out IPython magic to ensure Python compatibility.
# %%writetemplate /content/yolov5/models/custom_yolov5s.yaml
# 
# # parameters
# nc: {num_classes}  # number of classes
# depth_multiple: 0.33  # model depth multiple
# width_multiple: 0.50  # layer channel multiple
# 
# # anchors
# anchors:
#   - [10,13, 16,30, 33,23]  # P3/8
#   - [30,61, 62,45, 59,119]  # P4/16
#   - [116,90, 156,198, 373,326]  # P5/32
# 
# # YOLOv5 backbone
# backbone:
#   # [from, number, module, args]
#   [[-1, 1, Focus, [64, 3]],  # 0-P1/2
#    [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
#    [-1, 3, BottleneckCSP, [128]],
#    [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
#    [-1, 9, BottleneckCSP, [256]],
#    [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
#    [-1, 9, BottleneckCSP, [512]],
#    [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
#    [-1, 1, SPP, [1024, [5, 9, 13]]],
#    [-1, 3, BottleneckCSP, [1024, False]],  # 9
#   ]
# 
# # YOLOv5 head
# head:
#   [[-1, 1, Conv, [512, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#    [[-1, 6], 1, Concat, [1]],  # cat backbone P4
#    [-1, 3, BottleneckCSP, [512, False]],  # 13
# 
#    [-1, 1, Conv, [256, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#    [[-1, 4], 1, Concat, [1]],  # cat backbone P3
#    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)
# 
#    [-1, 1, Conv, [256, 3, 2]],
#    [[-1, 14], 1, Concat, [1]],  # cat head P4
#    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)
# 
#    [-1, 1, Conv, [512, 3, 2]],
#    [[-1, 10], 1, Concat, [1]],  # cat head P5
#    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)
# 
#    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
#   ]

"""# Traning proecess:"""



# Commented out IPython magic to ensure Python compatibility.
# # train yolov5s on custom data for 50 epochs
# # time its performance
# %%time
# %cd /content/yolov5
# 
# !python train.py --img 416 --batch 16 --epochs 50 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard
# logs save in the folder "runs"
# %load_ext tensorboard
# %tensorboard --logdir runs

from utils.plots import plot_results  # plot results.txt as results.png
from IPython.display import Image

Image(filename='/content/yolov5/runs/train/yolov5s_results2/results.png', width=1000)  # view results.png

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/yolov5s_results2/val_batch0_labels.jpg', width=900)

"""# Using the model for detection:

Using Detect.py passing the image and get predections:
"""

# #Usage - sources:
#     $ python detect.py --weights yolov5s.pt --source 0                               # webcam
#                                                      img.jpg                         # image
#                                                      vid.mp4                         # video
#                                                      screen                          # screenshot
#                                                      path/                           # directory
#                                                      list.txt                        # list of images
#                                                      list.streams                    # list of streams
#                                                      'path/*.jpg'                    # glob
#                                                      'https://youtu.be/Example'  # YouTube
#                                                      'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

# Usage - formats:
#     $ python detect.py --weights yolov5s.pt                 # PyTorch
#                                  yolov5s.torchscript        # TorchScript
#                                  yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
#                                  yolov5s_openvino_model     # OpenVINO
#                                  yolov5s.engine             # TensorRT
#                                  yolov5s.mlmodel            # CoreML (macOS-only)
#                                  yolov5s_saved_model        # TensorFlow SavedModel
#                                  yolov5s.pb                 # TensorFlow GraphDef
#                                  yolov5s.tflite             # TensorFlow Lite
#                                  yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
#                                  yolov5s_paddle_model       # PaddlePaddle
# """

# Commented out IPython magic to ensure Python compatibility.
# %%time
# %cd /content/yolov5
# 
# !python detect.py --weights /content/yolov5/runs/train/yolov5s_results2/weights/best.pt --source /content/1.jpg

from IPython.display import Image

print("The Test image:")
Image(filename='/content/1.jpg', width=900)

print("Result image:")
Image(filename='/content/yolov5/runs/detect/exp3/1.jpg', width=900)

